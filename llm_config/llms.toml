# llm_configs/llms.toml

[zhipuai]
model = "glm-4"
temperature = 0.7

[deepseek]
model = "deepseek-chat"
temperature = 0.7

[qwen]
model = "qwen-max"
temperature = 0.7
